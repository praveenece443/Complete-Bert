{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, AlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.bias', 'predictions.decoder.weight', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AlbertModel.from_pretrained('albert-base-v2')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Paris is a beautiful city\" \n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.8138, -0.2192,  0.7096,  ..., -0.3439,  0.3621,  1.2706],\n",
       "         [-0.4186, -1.1661,  0.0712,  ..., -0.2245,  1.6324, -0.7795],\n",
       "         [ 1.0005, -1.3621,  0.4578,  ...,  0.6159,  0.1886, -0.5999],\n",
       "         ...,\n",
       "         [ 0.0224, -1.0455,  0.6300,  ...,  0.5118,  0.0615, -0.6692],\n",
       "         [-0.3920, -0.8538,  0.1775,  ..., -0.2668,  1.7298, -0.1045],\n",
       "         [ 0.0680,  0.1246, -0.0667,  ..., -0.0867,  0.1263,  0.2187]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[ 0.7224, -0.7772,  0.8003, -0.8610,  0.5905, -0.8730,  0.7415, -0.7479,\n",
       "          0.7808, -0.9986,  0.9559,  0.7843, -0.2500, -0.9847, -0.9573, -0.7982,\n",
       "          0.7992,  0.7308,  0.9904, -0.6803, -0.6567, -0.9968,  0.9981,  0.9796,\n",
       "          0.7345, -0.7433,  0.7956, -0.9779, -0.9999, -0.7507, -1.0000,  0.7981,\n",
       "          0.7203,  0.7494,  0.7419, -0.7018,  0.8384,  0.9719, -0.7437,  0.7880,\n",
       "          0.7514, -0.9929, -0.8128,  0.7938,  0.7050,  0.7030,  0.9978, -0.9278,\n",
       "          0.5251, -0.7166, -0.7389, -0.7161, -0.7164, -0.9979,  0.5975,  0.8353,\n",
       "         -0.7793, -0.7461,  0.9996, -0.5426,  0.7246, -0.8359,  0.8411,  0.7649,\n",
       "         -0.7353,  0.6623,  0.7769,  0.9979, -0.7094,  0.9859,  0.7271,  0.8471,\n",
       "         -0.5570, -0.8334,  0.9886,  0.7769,  0.7587,  0.7227,  0.6249, -0.9526,\n",
       "          0.8711,  0.8289, -0.7726,  0.8137, -0.9498, -0.9688,  0.8602, -0.9999,\n",
       "          0.7923,  0.9025,  0.7680,  0.8351, -0.7137, -1.0000,  0.7363, -0.7911,\n",
       "         -0.9993,  0.8340,  0.7106, -0.7374,  0.9576, -0.7254,  0.8150, -0.8557,\n",
       "         -0.7170, -0.7291,  0.6962,  0.8361,  0.7224,  0.9991, -0.9753, -0.7138,\n",
       "          0.6829,  0.9955, -0.7671,  0.6347, -0.7912,  0.7460, -0.9827,  0.7852,\n",
       "          0.7040, -0.1079,  0.6881, -0.6429,  0.7800,  0.4122,  0.7194, -0.9471,\n",
       "          0.9862, -0.9626,  0.6430,  0.6774, -0.9999,  0.5604,  0.8088,  0.9928,\n",
       "         -0.6616, -0.7619, -0.7775,  0.7533,  0.8783, -0.7240,  0.7609, -0.7769,\n",
       "         -0.7338,  0.6773,  0.0912, -0.6572,  0.7076,  0.9773, -0.9169,  0.9734,\n",
       "          0.2085, -0.9771, -0.9906,  0.2432,  0.9885, -0.9201,  0.8651, -0.7193,\n",
       "         -0.7003, -0.9278, -0.9946, -0.7944, -0.9990, -0.8163,  0.9999, -0.1930,\n",
       "          0.9989, -0.9960, -0.7043,  0.7689, -0.7446,  0.9950,  0.7410,  0.7135,\n",
       "          0.7055,  0.6639, -0.7725, -0.6393,  0.9947, -0.9965,  0.7050,  0.7353,\n",
       "          0.9977,  0.7582,  0.8165, -0.7864,  0.7223, -0.6217, -0.7092, -0.1938,\n",
       "          0.8400,  0.7551,  1.0000, -0.7859,  0.9987, -0.9551,  0.9778, -0.9995,\n",
       "         -0.7632,  0.8384,  0.8621,  0.7368,  0.7355,  0.7735, -0.9367, -0.9989,\n",
       "         -0.9999, -0.7550, -0.9946,  0.9885, -0.9972,  0.7236, -0.9994,  0.9895,\n",
       "          0.9868, -0.7758,  1.0000, -0.7339,  0.8376,  0.7730, -0.9999,  0.9305,\n",
       "          0.7103,  0.7128, -0.1717, -0.7085,  0.9172, -0.9776, -0.9140, -0.2051,\n",
       "          0.7513, -1.0000, -0.9385, -0.7656,  0.8560,  0.7624,  0.7757, -0.9996,\n",
       "          1.0000,  0.7634, -0.7339, -0.7947, -0.3156,  1.0000, -0.6253, -0.4762,\n",
       "         -0.7312,  0.9990,  0.9450,  0.7789,  0.8328, -0.7622,  0.9477, -0.7152,\n",
       "         -0.9961, -0.8817, -0.9994,  0.7693, -0.9925,  0.8715, -0.6525, -0.9997,\n",
       "         -0.7616,  0.9510,  0.9990,  0.9990,  0.7394, -0.8528,  0.7403, -0.7736,\n",
       "          0.8243, -0.1249,  0.9944, -0.9675, -0.9818,  0.7797,  0.7894,  0.7122,\n",
       "         -0.7612, -0.6213,  0.7892, -0.7557,  0.9969, -0.9325,  1.0000, -0.9451,\n",
       "         -1.0000,  0.7267, -0.8274, -0.7594,  0.9900, -0.7450, -0.9982, -1.0000,\n",
       "          0.3815,  0.8038,  0.8953, -0.9958,  0.7794, -0.7692, -0.7352,  0.9971,\n",
       "          0.7693, -0.7382, -0.6886,  0.7376,  0.7269,  0.6991, -0.9555, -0.7681,\n",
       "         -0.1668, -0.9984, -0.7615, -0.8575, -0.7244, -0.4204,  0.9790,  0.9808,\n",
       "         -0.7254, -0.8552,  0.9984, -0.9941,  0.7918, -1.0000,  0.7950, -0.9998,\n",
       "         -0.9993, -0.8347, -0.8548, -0.7172, -0.7572, -0.9781,  0.7636, -0.9480,\n",
       "          0.7548, -0.8405,  0.9851,  0.9652, -1.0000, -0.7258, -0.9788,  0.7009,\n",
       "          0.7749,  0.7709, -0.4612, -0.8846,  0.7980, -0.9381,  0.7394,  0.8681,\n",
       "         -0.8043,  0.9029, -0.7106,  0.7470, -0.9469, -0.6276, -0.7369,  0.9610,\n",
       "          0.9994, -0.8562, -0.7135,  0.7272, -0.4216,  0.9720, -0.9932,  0.9868,\n",
       "         -0.9997, -0.8347, -0.9998,  0.9999,  0.9767,  0.0415, -0.7640, -0.9886,\n",
       "         -0.9931,  0.7840, -0.7596, -0.7051, -0.7549,  0.9862,  0.7316,  0.9743,\n",
       "         -0.7911,  0.0445,  0.6858,  0.9497, -0.9971,  0.9769, -0.8670, -0.7322,\n",
       "          0.9495,  1.0000, -0.7690,  0.7300, -0.9823, -0.9990, -0.8081,  0.7458,\n",
       "          0.9959, -0.6795, -0.8516,  0.9781,  0.9947, -0.9992,  0.8123,  0.9948,\n",
       "          0.9861,  0.7945,  0.7871,  0.9673,  0.8393,  0.7366,  0.9869, -0.7220,\n",
       "          1.0000, -0.9862, -0.9993,  0.9976, -0.6953,  0.9789, -0.7328,  0.6968,\n",
       "         -0.6126,  0.7357, -0.7802, -0.7568,  0.7022,  0.3073,  0.7772,  0.9966,\n",
       "          0.7171, -0.9986, -1.0000,  0.7096,  0.8191,  0.8185, -0.6719,  0.9190,\n",
       "         -0.7262,  0.3196, -0.8039, -0.7543,  0.7435, -1.0000,  1.0000, -0.9548,\n",
       "          0.9992, -0.7361,  0.9704,  0.1776,  0.9924, -0.8289, -1.0000, -0.7986,\n",
       "         -0.9999,  0.7537, -0.6902, -0.9658, -0.7310,  0.7304, -0.7336,  0.9974,\n",
       "          0.7082, -0.8138, -0.9952,  1.0000, -0.8670, -0.9989,  0.7049,  0.7729,\n",
       "          0.7500,  0.7590,  0.7110,  0.7410, -0.8590, -0.7598,  0.9498, -0.9967,\n",
       "          0.9032, -0.9689,  0.9722, -0.7570, -0.7293,  0.8937,  0.9999,  0.9988,\n",
       "         -0.2488, -1.0000, -0.9865, -0.9989, -0.9964,  0.7599, -0.9701,  0.9808,\n",
       "         -0.7332, -0.7095,  0.9706,  0.8850, -0.6994, -0.7052, -0.9052, -0.8281,\n",
       "         -0.7822, -0.9718,  0.7752, -0.9999, -0.3802, -0.9769, -0.9965,  0.3829,\n",
       "         -0.9985,  0.7149, -1.0000,  0.3025, -0.8063, -0.1868, -0.7352,  0.7490,\n",
       "          0.6806, -0.7081,  0.6707,  0.9988, -0.7919,  1.0000,  0.9999,  0.8639,\n",
       "          0.8133, -0.9562, -0.7732,  0.9998, -0.6207, -0.8877,  0.9579, -0.9371,\n",
       "          0.1371, -0.9652,  0.9929, -0.8892, -0.9114, -0.9928, -0.8065, -0.9999,\n",
       "         -0.9999, -1.0000,  0.7509,  0.9632, -0.9664,  1.0000,  0.8148, -0.8262,\n",
       "          0.9999,  0.7388, -0.9484,  0.7283, -0.7596,  1.0000, -0.7068,  0.8150,\n",
       "         -0.8295, -0.9981,  0.9922,  0.8740, -0.7122, -0.7262, -0.9844, -0.5314,\n",
       "          0.6351, -0.6955,  0.7873,  1.0000, -0.9718,  0.7086, -0.8289,  0.7452,\n",
       "         -0.9476,  0.6708,  0.0632, -0.2099, -0.9702, -0.9953,  0.9999,  0.7795,\n",
       "          0.8124,  0.7687,  0.8612, -0.6899,  1.0000, -1.0000, -0.7664,  0.7255,\n",
       "         -0.9652,  0.6630, -0.6493, -0.8251,  0.7208,  0.9994, -0.7153,  0.9999,\n",
       "          0.3351,  0.8033,  0.8043,  0.7468,  0.7260,  0.9999,  0.7648, -0.9351,\n",
       "         -0.7116, -0.7383, -0.7007,  0.9995,  0.9993, -0.8757, -0.6855, -0.7209,\n",
       "         -0.9436,  0.9940,  0.9670,  0.9972,  0.9946,  0.8168, -0.6849, -0.9937,\n",
       "          0.9969,  0.9110, -0.7560,  0.5712,  0.8197, -0.7495,  0.8756,  0.9221,\n",
       "         -0.8956,  0.3033,  0.7721,  0.9999,  0.9989, -0.7368,  0.8835, -1.0000,\n",
       "         -0.7612,  0.9948, -0.8777,  0.7866,  0.9985, -1.0000, -0.7370, -0.7655,\n",
       "          0.9790,  0.9995,  0.7404,  0.7130, -0.6847, -0.8123,  0.9884,  0.7006,\n",
       "         -0.7268,  0.9917, -0.8219, -0.7280,  0.7859,  0.7846,  0.9999,  0.8557,\n",
       "         -0.9815, -0.7854,  0.7482, -0.7936,  0.9493, -0.9995, -0.7210,  0.6687,\n",
       "         -0.5170,  0.6945,  0.9547,  0.7845, -0.7598, -0.9974,  0.7312,  0.9133,\n",
       "          0.7490,  0.9994,  0.7192, -0.0250,  0.8014,  0.9285, -0.1576,  0.8233,\n",
       "         -0.9966,  0.7462, -0.9280,  0.7674, -0.8245, -0.9941, -0.8420,  0.7525,\n",
       "          0.9518,  0.8056,  0.7487,  0.7068, -0.8249,  0.7915,  0.7510,  0.7009,\n",
       "         -0.6963, -0.8303, -0.8060, -0.9999,  0.7211,  0.6785,  0.5523,  0.7903,\n",
       "         -0.7438, -0.5739,  0.7840, -0.7032,  0.8094,  0.3007, -1.0000, -0.8051,\n",
       "         -0.9376, -0.8021,  0.7449, -0.7333,  0.7807, -0.6626, -1.0000, -0.4423,\n",
       "          0.7258, -0.9768,  0.7850, -0.9781,  0.7076,  0.9999,  0.9999, -0.9841,\n",
       "          0.7305, -0.9994, -0.7776, -0.8297, -1.0000,  0.7449,  0.9998,  0.1213,\n",
       "          0.7092, -0.9844, -0.4181,  0.9991, -0.9801, -0.8433,  0.7511, -0.7634,\n",
       "         -0.9999,  0.9736,  0.8016,  0.7499,  0.7720, -0.9891, -0.8013,  0.5905,\n",
       "         -0.9853,  0.7220,  0.9997, -0.7441,  0.7091, -0.7260, -0.9997,  0.7724]],\n",
       "       grad_fn=<TanhBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8138, -0.2192,  0.7096,  ..., -0.3439,  0.3621,  1.2706],\n",
      "         [-0.4186, -1.1661,  0.0712,  ..., -0.2245,  1.6324, -0.7795],\n",
      "         [ 1.0005, -1.3621,  0.4578,  ...,  0.6159,  0.1886, -0.5999],\n",
      "         ...,\n",
      "         [ 0.0224, -1.0455,  0.6300,  ...,  0.5118,  0.0615, -0.6692],\n",
      "         [-0.3920, -0.8538,  0.1775,  ..., -0.2668,  1.7298, -0.1045],\n",
      "         [ 0.0680,  0.1246, -0.0667,  ..., -0.0867,  0.1263,  0.2187]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mytokenizer\\\\tokenizer_config.json',\n",
       " 'mytokenizer\\\\special_tokens_map.json',\n",
       " 'mytokenizer\\\\spiece.model',\n",
       " 'mytokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('myalbert')\n",
    "tokenizer.save_pretrained('mytokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "\n",
    "model = AlbertModel.from_pretrained('myalbert')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('mytokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
